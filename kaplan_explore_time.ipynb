{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Colenda Items Over Time\n",
    "\n",
    "[Colenda Digital Repository at Penn Libraries](https://colenda.library.upenn.edu/) is a digital repository for digitized and born-digital material. It provides direct access and long-term stewardship for these important resources. Much of Colendaâ€™s content consists of materials owned and digitized by the Penn Libraries, including significant collections that have been donated.\n",
    "\n",
    "In this notebook we'll explore the temporal dimensions of data harvested from Colenda. When were items created, collected, or used? To do that we'll extract the nested temporal data, see what's there, and create a few charts.\n",
    "\n",
    "[See here](kaplan_explore_records.ipynb) for an introduction to exploring Colenda data, and [here to explore spatial dimensions](kaplan_explore_places.ipynb) of the data.\n",
    "\n",
    "* [Import What We Need](#Import-What-We-Need)\n",
    "* [Load the Data](#Load-the-Data)\n",
    "* [Concatenate and Split `metadata.date` Fields](#Concatenate-and-Split-metadata.date-Fields)\n",
    "* [Explore Items by Year](#Explore-Items-By-Year)\n",
    "* [Explore Items Distributed Over Time](#Explore-Items-Distributed-Over-Time)\n",
    "* [Focus on Items in a Particular Year](#Focus-on-Items-in-a-Particular-Year)\n",
    "* [Explore Items by Year and Type](#Explore-Items-by-Year-and-Type)\n",
    "* [Explore Items by Year and Location](#Explore-Items-by-Year-and-Location)\n",
    "* [Need Help?](#Need-Help?)\n",
    "* [Credits](#Credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p><b>Yellow blocks like this provide additional information about Python and Jupyter notebooks.</b></p>\n",
    "    \n",
    "<p>If you haven't used one of these notebooks before, they're basically web pages in which you can write, edit, and run live code. They're meant to encourage experimentation, so don't feel nervous. Just try running a few cells and see what happens!</p>\n",
    "\n",
    "<p>\n",
    "    Some tips:\n",
    "    <ul>\n",
    "        <li>Code cells have boxes around them.</li>\n",
    "        <li>To run a code cell click on the cell and then hit <b>Shift+Enter</b>. The <b>Shift+Enter</b> combo will also move you to the next cell, so it's a quick way to work through the notebook.</li>\n",
    "        <li>While a cell is running a <b>*</b> appears in the square brackets next to the cell. Once the cell has finished running the asterix will be replaced with a number.</li>\n",
    "        <li>In most cases you'll want to start from the top of notebook and work your way down running each cell in turn. Later cells might depend on the results of earlier ones.</li>\n",
    "        <li>To edit a code cell, just click on it and type stuff. Remember to run the cell once you've finished editing.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "<p><b>Is this thing on?</b> If you can't edit or run any of the code cells, you might be viewing a static (read only) version of this notebook. Click here to <a href=\"https://mybinder.org/v2/gh/GLAM-Workbench/national-museum-australia/master?urlpath=lab%2Ftree%2Fexplore_collection_object_over_time.ipynb\">load a <b>live</b> version</a> running on Binder.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import What We Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <p>In order to use this notebook, you first need to `import` modules and packages from Python. These are units of code with specific tools or skills that we use in the script.</p>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>If you're running this notebook on your computer, you may need to first `import` these modules within your Python interpreter. Find assistance for that <a href=\"https://packaging.python.org/tutorials/installing-packages/\">here</a>.</p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipyleaflet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d3e7f6fe8641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# IpyLeaflet is a Python library that enables interactive geospatial data visualization in Jupyter Notebook.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipyleaflet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPopup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMarkerCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# IpyWidgets is a Python library that enables interactive HTML widgets for Jupyter notebooks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipyleaflet'"
     ]
    }
   ],
   "source": [
    "# Pandas is a Python package that provides numerous tools for data analysis. \n",
    "import pandas as pd\n",
    "\n",
    "# IpyLeaflet is a Python library that enables interactive geospatial data visualization in Jupyter Notebook.\n",
    "from ipyleaflet import Map, Marker, Popup, MarkerCluster\n",
    "\n",
    "# IpyWidgets is a Python library that enables interactive HTML widgets for Jupyter notebooks.\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Altair is a Python library for declarative statistical visualization. \n",
    "import altair as alt\n",
    "\n",
    "# IPython is a Python interpreter to display content.\n",
    "from IPython.display import display, HTML, FileLink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pre-harvested dataset from Colenda includes every gift of Arnold and Deanne Kaplan, which covers two collections. In this notebook we will only work with records from the Arnold and Deanne Kaplan Collection of **Early American Judaica**. Let's load our data into Python using [Pandas](https://www.w3schools.com/python/pandas/default.asp), and then filtering on the Early American Judaica collection  by using the `metadata.collection[1]` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a dataframe (a two-dimensional data structure with rows and columns)\n",
    "df = pd.read_csv(\"kaplan-test-data.csv\", encoding= 'unicode_escape')\n",
    "\n",
    "# Print the number of rows in the dataframe\n",
    "print('There are {:,} items in this dataset from Colenda.'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>You may see a warning appear above stating that columns having \"mixed types\". This means that the CSV columns contain a mix of strings and integers. When converting the CSV into a dataframe, Python wasn't sure how to declare the column type. It's OK to ignore this warning for now - we may need to state directly this information later.<p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for items from the Early American Judaica Collection. \n",
    "df = df.loc[df['metadata.collection[1]'] == \"Arnold and Deanne Kaplan Collection of Early American Judaica (University of Pennsylvania)\"]\n",
    "\n",
    "# Return the first 5 rows of the dataframe.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate and Split `metadata.date` Fields\n",
    "\n",
    "Specific dates or years are linked to items through the `metadata.date` columns. Each item may have multiple multiple dates associated with it. For comparative and quantitative data analysis, we need to split those items into multiple rows instead of columns.\n",
    "\n",
    "We'll write two **functions** help us do that: \n",
    "* `tidy_split` splits the values of each cell on a \"|\" so that there is one split value per row, and \n",
    "* `tidy_concat` concatenates (joins) the values of columns that begin with a similar phrase into one cell with a \"|\" before using `tidy_split`. \n",
    "\n",
    "Now instead of having one row for each item with multiple dates, we can have one row for each date associated with an item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>A function is a block of reusable code that is used to perform a single, related action. Learn more about functions <a href=\"https://www.w3schools.com/python/python_functions.asp\">here</a>).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the values of a column and expand so that the new DataFrame has one split value per row. Filters rows where column is empty. \n",
    "def tidy_split(df, column, sep='|', keep=False):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the column to split and expand\n",
    "    column : str\n",
    "        the column to split and expand\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "    keep : bool\n",
    "        whether to retain the presplit value as its own row\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        values = presplit.split(sep)\n",
    "        if keep and len(values) > 1:\n",
    "            indexes.append(i)\n",
    "            new_values.append(presplit)\n",
    "        for value in values:\n",
    "            indexes.append(i)\n",
    "            new_values.append(value)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the values of columns beginnigng with a string and then use the tidy_split function to expand so that the new DataFrame has one split value per row.\n",
    "def tidy_concat(df, column_starts_with, sep=\"|\"):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the columns to split and expand\n",
    "    column_starts_with : str\n",
    "        the string at the beginning of the column(s) to split\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    list_of_columns = df.columns.to_list()\n",
    "    columns_to_concat = [x for x in list_of_columns if x.startswith(column_starts_with)]\n",
    "    df[column_starts_with] = df[columns_to_concat[0]]\n",
    "    for column in columns_to_concat[1:]:\n",
    "        df[column_starts_with] = df[column_starts_with].astype(str) + sep + df[column].astype(str)\n",
    "    new_df = tidy_split(df, column_starts_with, sep='|')\n",
    "    new_df = new_df.drop(columns_to_concat, axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined these the `tidy_concat` and `tidy_split` functions, we can use them to concatenate the multiple `metadata.date` columns into one column, and then split it so that the new dataframe has one split vavlue per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the values of columns beginnigng with a string and then use the tidy_split function to expand so that the new DataFrame has one split value per row.\n",
    "df_dates = tidy_concat(df, 'metadata.date', sep='|')\n",
    "\n",
    "# Filter the dataframe to only include dates that are NOT 'unknown'\n",
    "df_dates = df_dates[df_dates[\"metadata.date\"]!='unknown']\n",
    "\n",
    "# Filter the datafarme to only include the dates are NOT 'nan' (not a number)\n",
    "df_dates = df_dates[df_dates[\"metadata.date\"]!='nan']\n",
    "\n",
    "# Report the dimensionality of the dataframe (number of rows, number of columns).\n",
    "df_dates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "How many **unique** dates are represented in the collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1b7ad4d12841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Drop the duplicate dates from the dataframe and report the dimensionality of the dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munique_df_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_dates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata.date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'There are {:,} unique dates represented in the Arnold and Deanne Kaplan Collection of Early American Judaica (University of Pennsylvania).'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_df_dates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dates' is not defined"
     ]
    }
   ],
   "source": [
    "# Drop the duplicate dates from the dataframe and report the dimensionality of the dataframe.\n",
    "unique_df_dates = df_dates.drop_duplicates(subset=['metadata.date']).shape\n",
    "\n",
    "print('There are {:,} unique dates represented in the Arnold and Deanne Kaplan Collection of Early American Judaica (University of Pennsylvania).'.format(unique_df_dates[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Items by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates in this Colenda are formatted YYYY-MONTH-DD for a specific date. Let's extract years from the dates to make comparisons a bit easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a regular expression (a specific text pattern) to find the first four digits in the date fields\n",
    "df_dates['metadata.year'] = df_dates['metadata.date'].str.extract(r'^(\\d{4})').fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>A regular expressions is a sequence of characters that forms a search pattern, often used to find if a string contains a specific search pattern. Find more information about regular expression <a href=\"https://www.w3schools.com/python/python_regex.asp\">here</a>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the earliest `year` represented in the collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the minimum year (above 0) represented in the dataframe's Year column. \n",
    "earliest_year = df_dates.loc[df_dates['metadata.year'] > 0]['metadata.year'].min()\n",
    "\n",
    "print(earliest_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What items are from 1555? \n",
    "\n",
    "To identify these items, let's create a dataframe of items from 1555 and Then, we'll use the item's ARK identifier to generate links to an item's record in Colenda. More about ARK identifiers can be found in [Explore Colenda Records](kaplan_explore_records.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe called df_earliest, which is a subsection of the df_dates dataframe that contains only those where the year = earliest_year\n",
    "df_earliest = df_dates[df_dates['metadata.year'] == earliest_year]\n",
    "\n",
    "# Select the first row in the dataframe and access the Unique Identifier\n",
    "identifier = df_earliest.iloc[0]['unique_identifier']\n",
    "\n",
    "# Split the string up to the second occurrence of \"/\" and join all but the first element of the split string \n",
    "identifier = \"-\".join(identifier.split(\"/\", 2)[1:])\n",
    "\n",
    "# Display the link to the item in Colenda, with the item-specific URL and the item's title as the hyperlinked text \n",
    "display(HTML('<a href=\"https://colenda.library.upenn.edu/catalog/{}\">{}</a>'.format(identifier, df_earliest.iloc[0]['metadata.title[1]'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the latest year represented in the collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the maximum year of the years represented in the dataframe\n",
    "latest_year = df_dates['metadata.year'].max()\n",
    "\n",
    "print(latest_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many items are there from the latest year? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe called df_latest, which is a subsection of the df_dates dataframe that contains only those where the year = latest_year\n",
    "df_latest = df_dates[df_dates['metadata.year'] == latest_year]\n",
    "\n",
    "print('There are {:,} items from 1899 represented in the collection'.format(df_latest.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The year `1899` is used as a boundary year between two Kaplan Collections at the University of Pennsylvania Libraries: that of **Early American Judaica** (pre-1899) and **Modern American Judaica** (post-1899). What items are from 1899? \n",
    "\n",
    "Since there may be multiple items from 1899, we'll use a *for* loop to iterate over all the items from that year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>A <i>for</i> loop is used when iterating over a sequence in order. For each item in the sequence, the same action(s) will be performed. Find more information on <i>for</i> loops <a href=\"https://www.w3schools.com/python/python_for_loops.asp\">here</a></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "# Create a for loop that iterates over rows in the df_latest dataframe\n",
    "for idx, row in df_latest.iterrows():\n",
    "    \n",
    "# Select the first row in the dataframe and access the Unique Identifier \n",
    "    identifier = df_latest.iloc[count]['unique_identifier']\n",
    "\n",
    "# Split the string up to the second occurrence of \"/\" and join all but the first two elements of the split string \n",
    "    identifier = \"-\".join(identifier.split(\"/\", 2)[1:])\n",
    "\n",
    "# Display the link to the item in Colenda, with the item-specific URL and the item's title as the hyperlinked text\n",
    "    display(HTML('<a href=\"https://colenda.library.upenn.edu/catalog/{}\">{}</a>'.format(identifier, df_latest.iloc[count]['metadata.title[1]'])))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Items Distributed Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `Statistics` module to gather additional information about the years represented in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics is a Python module that you can use to calculate mathematical statistics of numeric data\n",
    "import statistics \n",
    "\n",
    "# Convert the values of the Year column to a list\n",
    "col_dates_list = df_dates['metadata.year'].tolist()\n",
    "\n",
    "# Remove all the 0 values from the list. \n",
    "col_dates_list = [i for i in col_dates_list if i != 0]\n",
    "\n",
    "# Sorted is a Python method that returns a numerically sorted list\n",
    "sorted(col_dates_list)\n",
    "\n",
    "# Calculate the median year in the list \n",
    "median = statistics.median(col_dates_list)\n",
    "\n",
    "# Calculate the mode year in the list\n",
    "mode = statistics.mode(col_dates_list)\n",
    "\n",
    "print('The median year is ' + str(median) + ' for items in the collection.')\n",
    "print('The most common year is ' + str(mode) + ' for items in the collection.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median and mode suggest that the majority of items in this collection are associated with the late nineteenth century. Let's make a chart of to see the number of items per year to see this as a visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many rows contain a year in the Year column. and save as a dataframe called year_counts\n",
    "year_counts = df_dates['metadata.year'].value_counts().to_frame().reset_index()\n",
    "year_counts.columns = ['Year', 'Count']\n",
    "year_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart (limit to years greater than 0)\n",
    "alt.Chart(year_counts.loc[year_counts['Year'] > 0]).mark_bar(size=2).encode(\n",
    "    \n",
    "    # Year on the X axis\n",
    "    x=alt.X('Year:Q', axis=alt.Axis(format='c', title='Year')),\n",
    "    \n",
    "    # Number of objects on the Y axis\n",
    "    y=alt.Y('Count:Q', title='Number of Items'),\n",
    "    \n",
    "    # Show details on hover\n",
    "    tooltip=[alt.Tooltip('Year:Q', title='Year'), alt.Tooltip('Count:Q', title='Count', format=',')]\n",
    ").properties(width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focus on Items in a Particular Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another notebook, we [used the `metadata.item_type` columns](kaplan_explore_records.ipynb#The-metadata.item_type-Fields) to learn about the types of items in the collection. Let's use it to see what types of objects are associated with a particular year. For the Kaplan Collection, we will use the year 1881.\n",
    "\n",
    "Let's explode `metadata.item_type[1]` and create a new dataframe with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the rows where the `metadata.item_type[1]` column is not null, and create a new dataframe that maintains four of the columns \n",
    "df_dates_types = df_dates.loc[df_dates['metadata.item_type[1]'].notnull()][['unique_identifier', 'metadata.title[1]', 'metadata.year', 'metadata.item_type[1]']]\n",
    "\n",
    "# Return the first 5 lines of the df_dates_types dataframe\n",
    "df_dates_types.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filter by year to see what types of items are associated in 1881."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe from the df_dates_types dataframe of the rows where the year is 1881. \n",
    "year_1881 = df_dates_types.loc[df_dates_types['metadata.year'] == 1881]\n",
    "year_1881.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the top twenty-five types of things created in 1881."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a Series containing counts of unique rows in the dataframe for each item type (up to 25)\n",
    "year_1881['metadata.item_type[1]'].value_counts()[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of items are 'Trade cards'. Let's look at one of the 'Trade cards' in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images in Colenda for these Trade cards are available under the [**International Image Interoperability Framework (IIIF)**](https://iiif.io/), which makes these images accessible and interoperable between image repositories. \n",
    "Let's take a look at the images of the clock. \n",
    "\n",
    "To display those images, we'll write two **functions** help us do that: \n",
    "* `_src_from_data` splits the values of each cell on a \"|\" so that there is one split value per row, and \n",
    "* `gallery` shows a set of images in a gallery that flexes with the width of the notebook. \n",
    "\n",
    "These functions for working with IIIF images come from [BVMC Labs](http://data.cervantesvirtual.com/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode image bytes for inclusion in an HTML img element\n",
    "# Requests is a Python package that allows you to send HTTP/1.1 requests.\n",
    "import requests\n",
    "\n",
    "def _src_from_data(data):\n",
    "    img_obj = Image(data=data)\n",
    "    for bundle in img_obj._repr_mimebundle_():\n",
    "        for mimetype, b64value in bundle.items():\n",
    "            if mimetype.startswith('image/'):\n",
    "                return f'data:{mimetype};base64,{b64value}'\n",
    "\n",
    "#  Shows a set of images in a gallery that flexes with the width of the notebook.\n",
    "def gallery(dictionary, row_height='auto'):\n",
    "    figures = []\n",
    "    for image, label in dictionary.items():\n",
    "        src = image\n",
    "        figures.append(f'''<figure style=\"margin: 5px !important;\">\n",
    "        <img src=\"{src}\" \n",
    "        style=\"height: {row_height}\">\n",
    "        <figcaption style=\"font-size: 1em\">{label}</figcaption>\n",
    "        </figure>''')\n",
    "    return HTML(data=f'''<div style=\"display: flex; flex-flow: row wrap; text-align: center;\">{''.join(figures)}</div>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate in the year_1881 dataframe of the rows where the type is Trade cards\n",
    "year_1881.loc[year_1881['metadata.item_type[1]'] == 'Trade cards'].head()\n",
    "\n",
    "# Select the first row in the dataframe. \n",
    "item = year_1881.loc[year_1881['metadata.item_type[1]'] == 'Trade cards'].iloc[0]\n",
    "\n",
    "# Select the first row in the dataframe and access the Unique Identifier. \n",
    "identifier = year_1881.iloc[count]['unique_identifier']\n",
    "\n",
    "# Split the string up to the second occurrence of \"/\" and join all but the first two elements of the split string. \n",
    "identifier = \"-\".join(identifier.split(\"/\", 2)[1:])\n",
    "\n",
    "# Create a string that is the link to the item-specific IIIF manifest. \n",
    "manifest = \"https://colenda.library.upenn.edu/phalt/iiif/2/\" + identifier + \"/manifest\"\n",
    "\n",
    "# Get the manifest\n",
    "r = requests.get(manifest)\n",
    "\n",
    "# Get the information about all the images for this item as a list \n",
    "results = r.json()[\"sequences\"][0]['canvases']\n",
    "\n",
    "# Create a dictionary to collect each image URL (key) and corresponding label (value) for this item. \n",
    "imagesDict = {}\n",
    "\n",
    "# Iterate over each image in the results list to extract the URL and label for the image, adding it to the lists above\n",
    "for i in range(len(results)):\n",
    "    label = results[i]['label']\n",
    "    resource = results[i]['images'][0]['resource']\n",
    "    images = resource['@id']\n",
    "    imagesDict[images] = label \n",
    "    \n",
    "# Display the link to the item in Colenda, with the item-specific URL and the item's title as the hyperlinked text. \n",
    "display(HTML('<a href=\"https://colenda.library.upenn.edu/catalog/{}\">{}</a>'.format(identifier, year_1881.iloc[count]['metadata.title[1]'])))\n",
    "\n",
    "# Display the images as a gallery    \n",
    "gallery(imagesDict, row_height='150px')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Items by Year and Type\n",
    "\n",
    "Now that we have a dataframe that combines creation dates with object types, we can look at how the creation of particular object types changes over time. Let's look at the 1880s as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe containing the years 1880-1889\n",
    "df_1880s = df_dates_types.loc[(df_dates_types['metadata.year'] > 1879) & (df_dates_types['metadata.year'] < 1890)]\n",
    "\n",
    "#Create a list of columns to keep\n",
    "col_list = ['metadata.year', 'metadata.item_type[1]']\n",
    "\n",
    "# Save the dataframe to contain only the columns in col_list\n",
    "df_1880s1 = df_1880s[col_list]\n",
    "\n",
    "# Group the dataframe by the columns Year and Type to calculate the number of elements, and save as column `Count`\n",
    "df_1880s1 =  df_1880s1.groupby(['metadata.year','metadata.item_type[1]']).size().reset_index(name=\"Count\")\n",
    "\n",
    "# Sort the column `Year` by its values\n",
    "df_1880s1 = df_1880s1.sort_values(by=['metadata.year'])\n",
    "\n",
    "df_1880s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to rename the columns to remove the `.` or else the charts below won't work\n",
    "df_1880s = df_1880s.rename(columns={\"metadata.year\": \"year\", \"metadata.item_type[1]\": \"additionalType\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stacked bar chart\n",
    "alt.Chart(df_1880s).mark_bar(size=3).encode(\n",
    "    \n",
    "    # Year on the X axis\n",
    "    x=alt.X('year:Q', axis=alt.Axis(format='c', title='Year')),\n",
    "    \n",
    "    # Number of objects on the Y axis\n",
    "    y=alt.Y('count()', title='Number of objects'),\n",
    "    \n",
    "    # Color according to the type\n",
    "    color='additionalType:N',\n",
    "    \n",
    "    # Details on hover\n",
    "    tooltip=[alt.Tooltip('additionalType:N', title='Type'), alt.Tooltip('year:Q', title='Year'), alt.Tooltip('count():Q', title='Objects', format=',')]\n",
    ").properties(width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another way of charting changes in the creation of the most common object types over time.\n",
    "\n",
    "First we'll get the top ten object types (which have years) as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most common 10 values and convert to a list\n",
    "top_types = df_dates_types['metadata.item_type[1]'].value_counts()[:10].index.to_list()\n",
    "top_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use the list of `top_types` to filter the creation dates, so we only have events relating to those types of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only include records where the additionalType value is in the list of top_types\n",
    "df_top_types = df_dates_types.loc[(df_dates_types['metadata.year'] > 0) & (df_dates_types['metadata.item_type[1]'].isin(top_types))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts for year / type\n",
    "top_type_counts = df_top_types.groupby('metadata.year')['metadata.item_type[1]'].value_counts().to_frame()\n",
    "top_type_counts.columns = ['Count']\n",
    "top_type_counts.reset_index(inplace=True)\n",
    "print(top_type_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To chart this data, we're going to use circles for each point and create 'bubble lines' for each item type to show how the number of items collected for that type varied year by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns to remove the `.` - formulas do not work without them\n",
    "top_type_counts = top_type_counts.rename(columns={\"metadata.year\": \"year\", \"metadata.item_type[1]\": \"additionalType\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chart\n",
    "alt.Chart(top_type_counts).mark_circle(\n",
    "    \n",
    "    # Style the circles\n",
    "    opacity=0.8,\n",
    "    stroke='black',\n",
    "    strokeWidth=1\n",
    ").encode(\n",
    "    \n",
    "    # Year on the X axis\n",
    "    x=alt.X('year:Q', axis=alt.Axis(format='c', title='Year', labelAngle=0), scale=alt.Scale(zero=False)),\n",
    "    \n",
    "    # Object type on the Y axis\n",
    "    y=alt.Y('additionalType:N', title='Item Type'),\n",
    "    \n",
    "    # Size of the circles represents the number of objects\n",
    "    size=alt.Size('Count:Q',\n",
    "        scale=alt.Scale(range=[0, 2000]),\n",
    "        legend=alt.Legend(title='Number of Items')\n",
    "    ),\n",
    "    \n",
    "    # Color the circles by object type\n",
    "    color=alt.Color('additionalType:N'),\n",
    "    \n",
    "    # Provide type, year, and count details on hover\n",
    "    tooltip=[alt.Tooltip('additionalType:N', title='Type'), alt.Tooltip('year:Q', title='Year'), alt.Tooltip('Count:Q', title='Number of Items', format=',')]\n",
    ").properties(\n",
    "    width=700\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chart shows us how item types are distributed over time. Let's calculate the earliest year for each item type in the collection and save it to a CSV for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy is a library for adding support for manipulating and operating on large, multi-dimensional arrays\n",
    "import numpy as np\n",
    "\n",
    "# Group DataFrame by the `additionalType` columns and aggregate the year column for its minimum and maximum year\n",
    "top_type_counts_grouped = top_type_counts.groupby('additionalType').agg({'year' : [np.min, np.max]})\n",
    "\n",
    "# Write the top_type_counts_grouped dataframe to a comma-separated values (csv) file.\n",
    "top_type_counts_grouped.to_csv('colenda_item_type_years.csv', index=False)\n",
    "\n",
    "# Display a link to the CSV.\n",
    "display(FileLink('colenda_item_type_years.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Items by Year and Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In preparation for our the next Jupyter notebook, let's take a look atlocation data instead of item types. To chart this data we're going to use circles for each point and create 'bubble lines' for each state to show how the number of items varies over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to split the values of the `metadata.geographic_subject` column and expand so that the new dataframe has one split value per row.\n",
    "df_places = tidy_concat(df_dates, 'metadata.geographic_subject', sep='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to only include non-null values\n",
    "df_places = df_places[df_places['metadata.geographic_subject'].notna()]\n",
    "\n",
    "# Filter the dataframe to only include geographic subjects that start with `United States`\n",
    "df_usa = df_places[df_places['metadata.geographic_subject'].str.startswith(\"United States\")]\n",
    "\n",
    "# Filter the dataframe to only include values that have two dashes (drop anything more detailed than the State level)\n",
    "df_usa = df_usa[df_usa[\"metadata.geographic_subject\"].str.count(\"-\")==2]\n",
    "\n",
    "# Filter the dataframe to only include values that are not zero\n",
    "df_usa = df_usa.loc[df_usa[\"metadata.year\"] != 0]\n",
    "\n",
    "# Rename the columns to remove the `.` or else the charts below won't work\n",
    "df_usa = df_usa.rename(columns={'metadata.geographic_subject': 'geographic_subject','metadata.year':'year'})\n",
    "\n",
    "# Get the counts for year / geographics_subject\n",
    "df_usa_counts = df_usa.groupby('year')['geographic_subject'].value_counts().to_frame()\n",
    "df_usa_counts.columns = ['Count']\n",
    "df_usa_counts.reset_index(inplace=True)\n",
    "print(df_usa_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chart\n",
    "alt.Chart(df_usa_counts).mark_circle(\n",
    "    \n",
    "    # Style the circles\n",
    "    opacity=0.8,\n",
    "    stroke='black',\n",
    "    strokeWidth=1\n",
    ").encode(\n",
    "    \n",
    "    # Year on the X axis\n",
    "    x=alt.X('year:Q', axis=alt.Axis(format='c', title='Year', labelAngle=0), scale=alt.Scale(zero=False)),\n",
    "    \n",
    "    # Object type on the Y axis\n",
    "    y=alt.Y('geographic_subject:N', title='State'),\n",
    "    \n",
    "    # Size of the circles represents the number of objects\n",
    "    size=alt.Size('Count:Q',\n",
    "        scale=alt.Scale(range=[0, 2000]),\n",
    "        legend=alt.Legend(title='Number of Items')\n",
    "    ),\n",
    "    \n",
    "    # Color the circles by object type\n",
    "    #color=alt.Color('geographic_subject:N'),\n",
    "    \n",
    "    # Provide state, year, and count details on hover\n",
    "    tooltip=[alt.Tooltip('geographic_subject:N', title='State'), alt.Tooltip('year:Q', title='Year'), alt.Tooltip('Count:Q', title='Number of Items', format=',')]\n",
    ").properties(\n",
    "    width=700\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need Help?\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>For additional Python and Digital Scholarship resources:</p>\n",
    "    <ul>\n",
    "        <li><a href\"https://www.w3schools.com/python/pandas/default.asp\">Pandas Tutorial from W3 Schools</a></li>\n",
    "        <li><a href\"https://altair-viz.github.io/altair-tutorial/README.html\">Altair Tutorial from W3 Schools</a></li>\n",
    "        <li><a href=\"https://guides.library.upenn.edu/digital-scholarship\">Center for Research Data and Digital Scholarship</a></li>\n",
    "    </ul>\n",
    "    <p>For help with this notebook:</p>    \n",
    "<ul>\n",
    "    <li>If you encounter any errors in this notebook, you can open an issue on GitHub or email estene@upenn.edu and reference this notebook.</li>\n",
    "\n",
    "<li>If you encounter any errors while working with the collection metadata (an incorrect date or broken ARK identifier), you can email estene@upenn.edu.</li>\n",
    "\n",
    "<li>Colenda is still a beta service. If you encounter issues with accessing any of the IIIF images or links, visit\n",
    "    <a href=\"https://colenda.library.upenn.edu/\">Colenda</a></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Credits\n",
    "\n",
    "Created by [Emily Esten](https://www.library.upenn.edu/people/staff/emily-esten). \n",
    "\n",
    "Judaica Digital Humanities at the <a href=\"http://library.upenn.edu\">Penn Libraries</a> (also referred to as Judaica DH) is a robust program of projects and tools for experimental digital scholarship with Judaica collections, informed by digital humanities, Jewish studies, and cultural heritage approaches. Visit our [website](judaicadh.library.upenn.edu).\n",
    "\n",
    "The pre-harvested dataset for this notebook works with items from the **Arnold and Deanne Kaplan Collection of Early American Judaica**. Donated to the University of Pennsylvania Libraries in 2012 by the Kaplans, and growing each year, this collection teaches us about the everyday lives, families, communal institutions, religious organizations, voluntary associations,  businesses, and political circumstances of Jewish life throughout the western hemisphere over four centuries. More information about the collection can be found at [https://kaplan.exhibits.library.upenn.edu](https://kaplan.exhibits.library.upenn.edu). \n",
    "\n",
    "This notebook references existing code and Jupyter notebooks, including: \n",
    "* [GLAM Workbench for the National Museum of Australia](https://doi.org/10.5281/zenodo.3544747) sponsored by the [Humanities, Arts and Social Sciences (HASS) Data Enhanced Virtual Lab](https://tinker.edu.au/).\n",
    "* [Library of Congress Data Exploration: IIIF](https://github.com/LibraryOfCongress/data-exploration/blob/26510c3f4da0bc85dfa87e82141173b1830e9d64/IIIF.ipynb).\n",
    "* Gustavo Candela, MarÃ­a Dolores SÃ¡ez, Pilar Escobar, Manuel Marco-Such, & Rafael C.Carrasco. (2020, May 8). hibernator11/notebook-iiif-images: release1.1 (Version 1.1). Zenodo. [http://doi.org/10.5281/zenodo.3816611](https://zenodo.org/badge/latestdoi/255172461). \n",
    "* [Genes for Project Cognoma](https://github.com/cognoma/genes/blob/721204091a96e55de6dcad165d6d8265e67e2a48/2.process.py)\n",
    "\n",
    "\n",
    "This work is modeled after Tim Sherrat's work with the National Museum of Australia, which was issued under an MIT Licesnse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
