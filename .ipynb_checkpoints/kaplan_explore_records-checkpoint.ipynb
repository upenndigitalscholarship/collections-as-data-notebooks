{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Colenda Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "\n",
    "[Colenda Digital Repository at Penn Libraries](https://colenda.library.upenn.edu/) is a digital repository for digitized and born-digital material. It provides direct access and long-term stewardship for these important resources. Much of Colendaâ€™s content consists of materials owned and digitized by the Penn Libraries, including significant collections that have been donated.\n",
    "\n",
    "In this notebook we'll have a preliminary look at data harvested from Colenda. I'll focus here on the basic shape/stats of the data. Other notebooks will explore data from Colenda over [time](kaplan_explore_time.ipynb) and [space](kaplan_explore_places.ipynb).\n",
    "\n",
    "If you haven't already, you'll need to [download a pre-harvested dataset](unzip_preharvested_data.ipynb) for use with this notebook. \n",
    "\n",
    "* [Import What We Need](#Import-What-We-Need)\n",
    "* [Load the Data](#Load-the-Data)\n",
    "* [Reviewing the Data](#Reviewing-the-Data)\n",
    "* [Concatenate and Split Columns](#Concatenate-and-Split-Columns)\n",
    "* [The `metadata.item_type` Field](#The-metadata.item_type-Field)\n",
    "* [Access Images of Items in the Collection](#Access-Images-of-Items-in-the-Collection)\n",
    "* [Need Help?](#Need-Help?)\n",
    "* [Credits](#Credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p><b>Yellow blocks like this provide additional information about Python and Jupyter notebooks.</b></p>\n",
    "    \n",
    "<p>If you haven't used one of these notebooks before, they're basically web pages in which you can write, edit, and run live code. They're meant to encourage experimentation, so don't feel nervous. Just try running a few cells and see what happens!</p>\n",
    "\n",
    "<p>\n",
    "    Some tips:\n",
    "    <ul>\n",
    "        <li>Code cells have boxes around them.</li>\n",
    "        <li>To run a code cell click on the cell and then hit <b>Shift+Enter</b>. The <b>Shift+Enter</b> combo will also move you to the next cell, so it's a quick way to work through the notebook.</li>\n",
    "        <li>While a cell is running a <b>*</b> appears in the square brackets next to the cell. Once the cell has finished running the asterix will be replaced with a number.</li>\n",
    "        <li>In most cases you'll want to start from the top of notebook and work your way down running each cell in turn. Later cells might depend on the results of earlier ones.</li>\n",
    "        <li>To edit a code cell, just click on it and type stuff. Remember to run the cell once you've finished editing.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "<p><b>Is this thing on?</b> If you can't edit or run any of the code cells, you might be viewing a static (read only) version of this notebook. Click here to <a href=\"https://mybinder.org/v2/gh/GLAM-Workbench/national-museum-australia/master?urlpath=lab%2Ftree%2Fexplore_collection_object_over_time.ipynb\">load a <b>live</b> version</a> running on Binder.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import What We Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <p>In order to use this notebook, you first need to `import` modules and packages from Python.</p>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>These modules and packages are units of code with specific tools or skills that we use in the script. If you're running this notebook on your computer, you may need to first `import` these modules within your Python interpreter. Find assistance for that <a href=\"https://packaging.python.org/tutorials/installing-packages/\">here</a>.</p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is a Python package that provides numerous tools for data analysis. \n",
    "import pandas as pd\n",
    "\n",
    "# IPython is a Python interpreter to display content.\n",
    "from IPython.display import display, HTML, FileLink, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pre-harvested dataset from Colenda includes many gifts of [Arnold and Deanne Kaplan](https://kaplan.exhibits.library.upenn.edu/thekaplans), which is concentrated in two collections. In this notebook we will only work with records from the Arnold and Deanne Kaplan Collection of **Early American Judaica**. We can access those items by using the `metadata.collection[1]` column and filtering on the Early American Judaica collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11,367 items in this dataset from Colenda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (61,62,63,64,65,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Convert to a dataframe\n",
    "df = pd.read_csv(\"Kaplan_Test_2.csv\", encoding= 'unicode_escape')\n",
    "\n",
    "# Print the number of rows in the dataframe\n",
    "print('There are {:,} items in this dataset from Colenda.'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>You may see a warning appear above stating that columns having \"mixed types\". This means that the CSV columns contain a mix of strings and integers. When converting the CSV into a dataframe, Python wasn't sure how to declare the column type. It's OK to ignore this warning for now - we may need to state directly this information later.<p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'metadata.collection[1]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'metadata.collection[1]'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-96a7637d2ab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filter for items from the Early American Judaica Collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata.collection[1]'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Arnold and Deanne Kaplan Collection of Early American Judaica (University of Pennsylvania)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Return the first 5 rows of the dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'metadata.collection[1]'"
     ]
    }
   ],
   "source": [
    "# Filter for items from the Early American Judaica Collection. \n",
    "df = df.loc[df['metadata.collection[1]'] == \"Arnold and Deanne Kaplan Collection of Early American Judaica (University of Pennsylvania)\"]\n",
    "\n",
    "# Return the first 5 rows of the dataframe.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {:,} items in Colenda from the Arnold and Deanne Kaplan Collection of Early American Judaica (University of Pennsylvania).'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this dataset in a dataframe, we can manipulate it. \n",
    "\n",
    "This dataset contains **descriptive metadata** about the items in the collection, which provides information about the intellectual content of a digital object. Descriptive metadata documents and tracks the intellectual content of an item, as well as support the search and discovery of these items within Colenda. The most important field of descriptive metadata is a unique identifier that uniquely identifies the object. Other descriptive metadata fields may include title, author, date of publication, subject, publisher and description. \n",
    "\n",
    "What descriptive metadata fields is in this dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the column names and add it to list\n",
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a long list of columns! You'll notice some similar fields:\n",
    "\n",
    "* **metadata.call_number** includes the physical item's location in the library\n",
    "* **metadata.collection** includes the name of the collection(s) with which the item is associated\n",
    "* **metadata.contributor** includes any responsible for making contributions to the resource\n",
    "* **metadata.corporate_name** includes any businesses, organizations, or institutions that are mentioned or associated with the item \n",
    "* **metadata.date** includes any dates that appear on the item, or that may be associated with the item\n",
    "* **metadata.description** includes a short account of the item\n",
    "* **metadata.format** is the singular version of the *metadata.item_type'* fields\n",
    "* **metadata.geographic_subject** includes any geographic locations associated with the item\n",
    "* **metadata.identifier** includes any other \"names\" or unique terms used to refer to this item\n",
    "* **metadata.item_type** includes the genre(s) of the resource.\n",
    "* **metadata.language** includes any languages that appear on the item\n",
    "* **metadata.notes** includes any notes associated with the item\n",
    "* **metadata.personal_name** includes any individuals that are mentioned or associated with the item\n",
    "* **metadata.provenance** includes the history of the physical item\n",
    "* **metadata.publisher** includes the publisher of the item\n",
    "* **metadata.rights** includes information about rights held in and over the item\n",
    "* **metadata.subject** includes any terms used to categorize the item\n",
    "* **metadata.title** includes a short name given to the resource\n",
    "* **unique_identifier** is the [Archival Resource Key identifier](https://n2t.net/e/ark_ids.html) (more on this later)\n",
    "\n",
    "Not every item has a value for every column. Let's create a quick count of the number of values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count non-NA cells for each column (cells not missing data)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's express those counts as a percentage of the total number of records, and display them as a bar chart using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts for each column and convert to a new dataframe\n",
    "field_counts = df.count().to_frame().reset_index()\n",
    "\n",
    "# Change column headings\n",
    "field_counts.columns = ['Field', 'Count']\n",
    "\n",
    "# Calculate proportion of the total\n",
    "field_counts['Proportion'] = field_counts['Count'].apply(lambda x: x / df.shape[0])\n",
    "\n",
    "# Style the results as a barchart\n",
    "field_counts.style.bar(subset=['Proportion'], color='#d65f5f').format({'Proportion': '{:.2%}'.format})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate and Split Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the column headings appear multiple times, identified by a number at the end of it. For example, the `metadata.item_type` column appears twice, indicating there are two item types for some items. For comparative and quantitative data analysis, we may need to split those items into multiple rows instead of columns.\n",
    "\n",
    "Let's use `metadata.item_type` as an example of how we can concatenate and split these columns. How many items have more than one item type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many rows are not blank in the 'metadata.item_type[2]'' column\n",
    "df['metadata.item_type[2]'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at those items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filtered dataframe by 'metadata.item_type[2]', including only those that have data in that column\n",
    "df1 = df[df['metadata.item_type[2]'].notnull()]\n",
    "\n",
    "# Return the first 5 lines of the df1 dataframe\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to accurately count how many items of each item type are included in this dataset, we need to split the values in those cells into individual rows. \n",
    "\n",
    "We'll write two **functions** help us do that: \n",
    "* `tidy_split` splits the values of each cell on a \"|\" so that there is one split value per row\n",
    "* `tidy_concat` concatenates (combines) the values of columns that begin with a similar phrase into one cell with a \"|\" before using `tidy_split`. \n",
    "\n",
    "Now instead of having one row for each item with multiple types, we can have one row for each type associated with an item.\n",
    "\n",
    "The `tidy_split` function come from [Project Cognoma](http://cognoma.org/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p>A function is a block of reusable code that is used to perform a single, related action. Learn more about functions <a href=\"https://www.w3schools.com/python/python_functions.asp\">here</a>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the values of a column and expand so that the new DataFrame has one split value per row\n",
    "# Filters rows where column is empty \n",
    "def tidy_split(df, column, sep='|', keep=False):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the column to split and expand\n",
    "    column : str\n",
    "        the column to split and expand\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "    keep : bool\n",
    "        whether to retain the presplit value as it's own row\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        values = presplit.split(sep)\n",
    "        if keep and len(values) > 1:\n",
    "            indexes.append(i)\n",
    "            new_values.append(presplit)\n",
    "        for value in values:\n",
    "            indexes.append(i)\n",
    "            new_values.append(value)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the values of columns beginnigng with a string and then use the tidy_split function to expand so that the new DataFrame has one split value per row\n",
    "def tidy_concat(df, column_starts_with, sep=\"|\"):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the columns to split and expand\n",
    "    column_starts_with : str\n",
    "        the string at the beginning of the column(s) to split\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    list_of_columns = df.columns.to_list()\n",
    "    columns_to_concat = [x for x in list_of_columns if x.startswith(column_starts_with)]\n",
    "    df[column_starts_with] = df[columns_to_concat[0]]\n",
    "    for column in columns_to_concat[1:]:\n",
    "        df[column_starts_with] = df[column_starts_with].astype(str) + sep + df[column].astype(str)\n",
    "    new_df = tidy_split(df, column_starts_with, sep='|')\n",
    "    new_df = new_df.drop(columns_to_concat, axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to split the values of the Type column and expand so that the new DataFrame has one split value per row\n",
    "df = tidy_concat(df, 'metadata.item_type', sep='|')\n",
    "\n",
    "# Report the dimensionality of the dataframe (number of rows, number of columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `metadata.item_type` Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `metadata.item_type` field refers to the type of item: books, manuscripts, sound recordings, etc. Let's look at the 25 most common item types in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a Series containing counts of unique rows in the dataframe for each Type (up to 25 Types)\n",
    "df['metadata.item_type'].value_counts()[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nan` refers to empty values, meaning that there are no item types listed for those rows. \n",
    "Of all the item types that appear in the collection, how many item types only appear once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe called type_counts, which includes a Type column and a Count column\n",
    "type_counts = df['metadata.item_type'].value_counts().to_frame().reset_index().rename({'index': 'type', 'metadata.item_type': 'count'}, axis=1)\n",
    "\n",
    "# Locate the rows that have a 'unique' type, or a count of 1\n",
    "unique_types = type_counts.loc[type_counts['count'] == 1]\n",
    "\n",
    "# Print the number of rows in the dataframe\n",
    "print('There are {:,} items from the collection with unique item types.'.format(unique_types.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Let's save the complete list of types as a CSV file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the type_counts dataframe to a comma-separated values (csv) file.\n",
    "type_counts.to_csv('colenda_item_type_counts.csv', index=False)\n",
    "\n",
    "# Display a link to the CSV.\n",
    "display(FileLink('colenda_item_type_counts.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browsing the CSV, I noticed that there was one item with the type `Clocks`. Let's find some more out about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the item in the complete data set\n",
    "clocks = df.loc[df['metadata.item_type'].notnull()]['metadata.item_type'].apply(lambda x: 'Clocks' in x)\n",
    "clock = df.loc[df['metadata.item_type'].notnull()][clocks]\n",
    "clock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a link into the item's record in Colenda using its `unique_identifier`. The value in this column is an [Archival Resource Key identifier](https://n2t.net/e/ark_ids.html), designed to support long-term access to information objects. This identifier can be divided into three parts, separated by `/`: the ARK label, the collection of which the item is a part, and the unique identifier for the item within the collection.\n",
    "\n",
    "To create the link, we only need the second and third part of the unique identifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first row in the dataframe\n",
    "identifier = clock.iloc[0]['unique_identifier']\n",
    "\n",
    "# Split the string up to the second occurrence of \"/\" and join all but the first element of the split string \n",
    "identifier = \"-\".join(identifier.split(\"/\", 2)[1:])\n",
    "\n",
    "# Display the link to the item in Colenda, with the item-specific URL and the item's title as the hyperlinked text \n",
    "display(HTML('<a href=\"https://colenda.library.upenn.edu/catalog/{}\">{}</a>'.format(identifier, clock.iloc[0]['metadata.title[1]'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Images of Items in the Collection\n",
    "\n",
    "The images in Colenda for these items are available under the [**International Image Interoperability Framework (IIIF)**](https://iiif.io/), which makes these images accessible and interoperable between image repositories. \n",
    "\n",
    "To display those images, we'll write two **functions** help us do that: \n",
    "* `_src_from_data` splits the values of each cell on a \"|\" so that there is one split value per row, and \n",
    "* `gallery` shows a set of images in a gallery that flexes with the width of the notebook. \n",
    "\n",
    "These functions for working with IIIF images come from [BVMC Labs](http://data.cervantesvirtual.com/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode image bytes for inclusion in an HTML img element\n",
    "def _src_from_data(data):\n",
    "    img_obj = Image(data=data)\n",
    "    for bundle in img_obj._repr_mimebundle_():\n",
    "        for mimetype, b64value in bundle.items():\n",
    "            if mimetype.startswith('image/'):\n",
    "                return f'data:{mimetype};base64,{b64value}'\n",
    "\n",
    "#  Shows a set of images in a gallery that flexes with the width of the notebook.\n",
    "def gallery(dictionary, row_height='auto'):\n",
    "    figures = []\n",
    "    for image, label in dictionary.items():\n",
    "        src = image\n",
    "        figures.append(f'''<figure style=\"margin: 5px !important;\">\n",
    "        <img src=\"{src}\" \n",
    "        style=\"height: {row_height}\">\n",
    "        <figcaption style=\"font-size: 1em\">{label}</figcaption>\n",
    "        </figure>''')\n",
    "    return HTML(data=f'''<div style=\"display: flex; flex-flow: row wrap; text-align: center;\">{''.join(figures)}</div>''')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the images of the clock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests is a Python package that allows you to send HTTP/1.1 requests.\n",
    "import requests\n",
    "\n",
    "# Create a string that is the link to the item-specific IIIF manifest. \n",
    "manifest = \"https://colenda.library.upenn.edu/phalt/iiif/2/\" + identifier + \"/manifest\"\n",
    "\n",
    "# Get the manifest\n",
    "r = requests.get(manifest)\n",
    "\n",
    "# Get the information about all the images for this item as a list \n",
    "results = r.json()[\"sequences\"][0]['canvases']\n",
    "\n",
    "# Create a dictionary to collect each image URL (key) and corresponding label (value) for this item. \n",
    "imagesDict = {}\n",
    "\n",
    "# Iterate over each image in the results list to extract the URL and label for the image, adding it to the lists above\n",
    "for i in range(len(results)):\n",
    "    label = results[i]['label']\n",
    "    resource = results[i]['images'][0]['resource']\n",
    "    images = resource['@id']\n",
    "    imagesDict[images] = label \n",
    "    \n",
    "# Display the images as a gallery    \n",
    "gallery(imagesDict, row_height='150px')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice work! We can now use these basic instructions to explore more aspects of the collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need Help?\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>For additional Python and Digital Scholarship resources:</p>\n",
    "    <ul>\n",
    "        <li><a href\"https://www.w3schools.com/python/pandas/default.asp\">Pandas Tutorial from W3 Schools</a></li>\n",
    "        <li><a href\"https://altair-viz.github.io/altair-tutorial/README.html\">Altair Tutorial from W3 Schools</a></li>\n",
    "        <li><a href=\"https://guides.library.upenn.edu/digital-scholarship\">Center for Research Data and Digital Scholarship</a></li>\n",
    "    </ul>\n",
    "    <p>For help with this notebook:</p>    \n",
    "<ul>\n",
    "    <li>If you encounter any errors in this notebook, you can open an issue on GitHub or email estene@upenn.edu and reference this notebook.</li>\n",
    "\n",
    "<li>If you encounter any errors while working with the collection metadata (an incorrect date or broken ARK identifier), you can email estene@upenn.edu.</li>\n",
    "\n",
    "<li>Colenda is still a beta service. If you encounter issues with accessing any of the IIIF images or links, visit\n",
    "    <a href=\"https://colenda.library.upenn.edu/\">Colenda</a></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Credits\n",
    "\n",
    "Created by [Emily Esten](https://www.library.upenn.edu/people/staff/emily-esten). \n",
    "\n",
    "Judaica Digital Humanities at the <a href=\"http://library.upenn.edu\">Penn Libraries</a> (also referred to as Judaica DH) is a robust program of projects and tools for experimental digital scholarship with Judaica collections, informed by digital humanities, Jewish studies, and cultural heritage approaches. Visit our [website](judaicadh.library.upenn.edu).\n",
    "\n",
    "The pre-harvested dataset for this notebook works with items from the **Arnold and Deanne Kaplan Collection of Early American Judaica**. Donated to the University of Pennsylvania Libraries in 2012 by the Kaplans, and growing each year, this collection teaches us about the everyday lives, families, communal institutions, religious organizations, voluntary associations,  businesses, and political circumstances of Jewish life throughout the western hemisphere over four centuries. More information about the collection can be found at [https://kaplan.exhibits.library.upenn.edu](https://kaplan.exhibits.library.upenn.edu). \n",
    "\n",
    "This notebook references existing code and Jupyter notebooks, including: \n",
    "* [GLAM Workbench for the National Museum of Australia](https://doi.org/10.5281/zenodo.3544747) sponsored by the [Humanities, Arts and Social Sciences (HASS) Data Enhanced Virtual Lab](https://tinker.edu.au/).\n",
    "* [Library of Congress Data Exploration: IIIF](https://github.com/LibraryOfCongress/data-exploration/blob/26510c3f4da0bc85dfa87e82141173b1830e9d64/IIIF.ipynb).\n",
    "* Gustavo Candela, MarÃ­a Dolores SÃ¡ez, Pilar Escobar, Manuel Marco-Such, & Rafael C.Carrasco. (2020, May 8). hibernator11/notebook-iiif-images: release1.1 (Version 1.1). Zenodo. [http://doi.org/10.5281/zenodo.3816611](https://zenodo.org/badge/latestdoi/255172461). \n",
    "* [Genes for Project Cognoma](https://github.com/cognoma/genes/blob/721204091a96e55de6dcad165d6d8265e67e2a48/2.process.py)\n",
    "* https://mindtrove.info/jupyter-tidbit-image-gallery/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
